{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c70f8a76",
      "metadata": {
        "id": "c70f8a76"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dac98727",
      "metadata": {
        "id": "dac98727",
        "outputId": "8679d3e5-2605-4bda-bb08-b90a0d9042c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l==1.0.3\n",
            "  Downloading d2l-1.0.3-py3-none-any.whl.metadata (556 bytes)\n",
            "Collecting jupyter==1.0.0 (from d2l==1.0.3)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "Collecting numpy==1.23.5 (from d2l==1.0.3)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting matplotlib==3.7.2 (from d2l==1.0.3)\n",
            "  Downloading matplotlib-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting matplotlib-inline==0.1.6 (from d2l==1.0.3)\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting requests==2.31.0 (from d2l==1.0.3)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pandas==2.0.3 (from d2l==1.0.3)\n",
            "  Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting scipy==1.10.1 (from d2l==1.0.3)\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.7)\n",
            "Collecting qtconsole (from jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading qtconsole-5.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (25.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (11.3.0)\n",
            "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib==3.7.2->d2l==1.0.3)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (2.9.0.post0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from matplotlib-inline==0.1.6->d2l==1.0.3) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (2025.7.14)\n",
            "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting contourpy>=1.0.1 (from matplotlib==3.7.2->d2l==1.0.3)\n",
            "  Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l==1.0.3) (1.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.4.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.0.15)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (2.19.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.8.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (25.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.1)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading QtPy-2.4.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.25.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l==1.0.3) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l==1.0.3) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (25.1.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.14.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.26.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.1)\n",
            "Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading matplotlib-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qtconsole-5.6.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.0/125.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading QtPy-2.4.3-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.0/95.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests, qtpy, pyparsing, numpy, matplotlib-inline, jedi, scipy, pandas, contourpy, matplotlib, qtconsole, jupyter, d2l\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.3\n",
            "    Uninstalling pyparsing-3.2.3:\n",
            "      Successfully uninstalled pyparsing-3.2.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: matplotlib-inline\n",
            "    Found existing installation: matplotlib-inline 0.1.7\n",
            "    Uninstalling matplotlib-inline-0.1.7:\n",
            "      Successfully uninstalled matplotlib-inline-0.1.7\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.3\n",
            "    Uninstalling contourpy-1.3.3:\n",
            "      Successfully uninstalled contourpy-1.3.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "cvxpy 1.6.7 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 2.13.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.7.1 requires pandas>=2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.31.0 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.3 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.3 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "chex 0.1.90 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "arviz 0.22.0 requires matplotlib>=3.8, but you have matplotlib 3.7.2 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "arviz 0.22.0 requires pandas>=2.1.0, but you have pandas 2.0.3 which is incompatible.\n",
            "arviz 0.22.0 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\n",
            "jaxlib 0.5.3 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.3 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "geopandas 1.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed contourpy-1.3.2 d2l-1.0.3 jedi-0.19.2 jupyter-1.0.0 matplotlib-3.7.2 matplotlib-inline-0.1.6 numpy-1.23.5 pandas-2.0.3 pyparsing-3.0.9 qtconsole-5.6.1 qtpy-2.4.3 requests-2.31.0 scipy-1.10.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "matplotlib_inline",
                  "mpl_toolkits",
                  "numpy",
                  "pyparsing"
                ]
              },
              "id": "b69ee2601007460d8dfcbe3709d99cf4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install d2l==1.0.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57249b96",
      "metadata": {
        "origin_pos": 1,
        "id": "57249b96"
      },
      "source": [
        "# Pooling\n",
        ":label:`sec_pooling`\n",
        "\n",
        "In many cases our ultimate task asks some global question about the image,\n",
        "e.g., *does it contain a cat?*\n",
        ">Often we care about a property of the entire image—like “Is there a cat?”—rather than some small local detail.\n",
        "\n",
        "Consequently, the units of our final layer should be sensitive to the entire input.\n",
        ">Because the decision depends on features anywhere in the image, each neuron in the last layer needs to “see” or be influenced by the whole image.\n",
        "\n",
        "By gradually aggregating information, yielding coarser and coarser maps,\n",
        "we accomplish this goal of ultimately learning a global representation,\n",
        "while keeping all of the advantages of convolutional layers at the intermediate layers of processing.\n",
        ">We downsample (via pooling or strided convolution) to shrink feature‐map size step by step. This produces a compact “global” feature vector—yet we still get convolution’s benefits (local receptive fields, weight sharing) in earlier layers.\n",
        "\n",
        "The deeper we go in the network, the larger the receptive field (relative to the input) to which each hidden node is sensitive.\n",
        ">Neurons in deeper layers aggregate information from progressively wider patches of the original image. Their **receptive field** grows with network depth.\n",
        "\n",
        "\n",
        "Reducing spatial resolution accelerates this process, since the convolution kernels cover a larger effective area.\n",
        "> Downsampling makes each convolutional filter span more of the original image at once, so the receptive field expands faster.\n",
        "\n",
        "> **In a nutshell:**  \n",
        "Pooling (or other downsampling) helps later layers “see” the whole image more quickly—building a global understanding—while the early convolutional layers still capture rich local details.  \n",
        "\n",
        "\n",
        "Moreover, when detecting lower-level features, such as edges\n",
        "(as discussed in :numref:`sec_conv_layer`),\n",
        "we often want our representations to be somewhat invariant to translation.\n",
        "For instance, if we take the image `X`\n",
        "with a sharp delineation between black and white\n",
        "and shift the whole image by one pixel to the right,\n",
        "i.e., `Z[i, j] = X[i, j + 1]`,\n",
        "then the output for the new image `Z` might be vastly different.\n",
        "The edge will have shifted by one pixel.\n",
        "In reality, objects hardly ever occur exactly at the same place.\n",
        "In fact, even with a tripod and a stationary object,\n",
        "vibration of the camera due to the movement of the shutter\n",
        "might shift everything by a pixel or so\n",
        "(high-end cameras are loaded with special features to address this problem).\n",
        "\n",
        "This section introduces *pooling layers*,\n",
        "**which serve the dual purposes of\n",
        "mitigating the sensitivity of convolutional layers to location\n",
        "and of spatially downsampling representations.**\n",
        ">**Pooling** shrinks the spatial dimensions of feature maps (keeping resolutions small and computation light) **while retaining** the most important information, so deeper layers can efficiently build a global understanding of the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1d620804",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:38.208041Z",
          "iopub.status.busy": "2023-08-18T20:14:38.207378Z",
          "iopub.status.idle": "2023-08-18T20:14:41.246234Z",
          "shell.execute_reply": "2023-08-18T20:14:41.245322Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "1d620804"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3e7dfcb",
      "metadata": {
        "origin_pos": 5,
        "id": "b3e7dfcb"
      },
      "source": [
        "## Maximum Pooling and Average Pooling\n",
        "\n",
        "Like convolutional layers, *pooling* operators\n",
        "consist of a fixed-shape window that is slid over\n",
        "all regions in the input according to its stride,\n",
        "computing a single output for each location traversed\n",
        "by the fixed-shape window (sometimes known as the *pooling window*).\n",
        "However, unlike the cross-correlation computation\n",
        "of the inputs and kernels in the convolutional layer,\n",
        "the pooling layer contains no parameters (there is no *kernel*).\n",
        "Instead, pooling operators are deterministic,\n",
        "typically calculating either the maximum or the average value\n",
        "of the elements in the pooling window.\n",
        "These operations are called *maximum pooling* (*max-pooling* for short)\n",
        "and *average pooling*, respectively.\n",
        "\n",
        "*Average pooling* is essentially as old as CNNs. The idea is akin to\n",
        "downsampling an image. Rather than just taking the value of every second (or third)\n",
        "pixel for the lower resolution image, we can average over adjacent pixels to obtain\n",
        "an image with better signal-to-noise ratio since we are combining the information\n",
        "from multiple adjacent pixels. *Max-pooling* was introduced in\n",
        ":citet:`Riesenhuber.Poggio.1999` in the context of cognitive neuroscience to describe\n",
        "how information aggregation might be aggregated hierarchically for the purpose\n",
        "of object recognition; there already was an earlier version in speech recognition :cite:`Yamaguchi.Sakamoto.Akabane.ea.1990`. **In almost all cases, max-pooling, as it is also referred to,\n",
        "is preferable to average pooling.**\n",
        "\n",
        "In both cases, as with the cross-correlation operator,\n",
        "we can think of the pooling window\n",
        "as starting from the upper-left of the input tensor\n",
        "and sliding across it from left to right and top to bottom.\n",
        "At each location that the pooling window hits,\n",
        "it computes the maximum or average\n",
        "value of the input subtensor in the window,\n",
        "depending on whether max or average pooling is employed.\n",
        "\n",
        "\n",
        "![Max-pooling with a pooling window shape of $2\\times 2$. The shaded portions are the first output element as well as the input tensor elements used for the output computation: $\\max(0, 1, 3, 4)=4$.](http://d2l.ai/_images/pooling.svg)\n",
        ":label:`fig_pooling`\n",
        "\n",
        "The output tensor in :numref:`fig_pooling`  has a height of 2 and a width of 2.\n",
        "The four elements are derived from the maximum value in each pooling window:\n",
        "\n",
        "$$\n",
        "\\max(0, 1, 3, 4)=4,\\\\\n",
        "\\max(1, 2, 4, 5)=5,\\\\\n",
        "\\max(3, 4, 6, 7)=7,\\\\\n",
        "\\max(4, 5, 7, 8)=8.\\\\\n",
        "$$\n",
        "\n",
        "More generally, we can define a $p \\times q$ pooling layer by aggregating over\n",
        "a region of said size. Returning to the problem of edge detection,\n",
        "we use the output of the convolutional layer\n",
        "as input for $2\\times 2$ max-pooling.\n",
        "Denote by `X` the input of the convolutional layer input and `Y` the pooling layer output.\n",
        "\n",
        "Regardless of whether or not the values of `X[i, j]`, `X[i, j + 1]`,\n",
        "`X[i+1, j]` and `X[i+1, j + 1]` are different,\n",
        "the pooling layer always outputs `Y[i, j] = 1`.\n",
        "That is to say, using the $2\\times 2$ max-pooling layer,\n",
        "we can still detect if the pattern recognized by the convolutional layer\n",
        "moves no more than one element in height or width.\n",
        ">Here’s what’s going on:\n",
        "1. **Remember** that in this toy example, the convolutional layer’s output **X** is binary:\n",
        "   $$\n",
        "   X[i,j] =\n",
        "   \\begin{cases}\n",
        "     1, & \\text{if the localized pattern (e.g.\\ an edge) matches exactly at location }(i,j),\\\\\n",
        "     0, & \\text{otherwise.}\n",
        "   \\end{cases}\n",
        "   $$\n",
        "2. **Max-pooling** over a $2\\times2$ window at output location $(i,j)$ is defined as\n",
        "   $$\n",
        "   Y[i,j] \\;=\\;\\max\\bigl(X[i,j],\\;X[i,j+1],\\;X[i+1,j],\\;X[i+1,j+1]\\bigr).\n",
        "   $$\n",
        "3. Now, if the pattern you’re detecting shifts by at most one pixel in **any** direction, **exactly one** of those four $X$–values will be 1 (the position where the filter still lines up perfectly), and the other three will be 0.  Hence:\n",
        "   $$\n",
        "   Y[i,j]\n",
        "   = \\max\\bigl(\\underbrace{0,0,1,0}_{\\text{one of these is 1}}\\bigr)\n",
        "   = 1.\n",
        "   $$\n",
        "   It doesn’t matter **which** of the four positions holds that 1—pooling takes the maximum—so **regardless** of how the pattern shifts (so long as it stays within that $2\\times2$ block), the pooled output is $1$.\n",
        "> ### Intuition\n",
        "* **Convolution** gives you a “hit” map $X$: 1 where it sees your exact pattern, 0 elsewhere.\n",
        "* **Max-pooling** then “remembers” whether **any** nearby convolution location fired.\n",
        "* As long as the pattern moves no more than one pixel, at least one of those four spots will fire, so the pooled output stays 1—thus introducing a bit of shift-invariance.\n",
        "\n",
        "\n",
        "In the code below, we (**implement the forward propagation\n",
        "of the pooling layer**) in the `pool2d` function.\n",
        "This function is similar to the `corr2d` function\n",
        "in :numref:`sec_conv_layer`.\n",
        "However, no kernel is needed, computing the output\n",
        "as either the maximum or the average of each region in the input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b6b758a3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:41.250338Z",
          "iopub.status.busy": "2023-08-18T20:14:41.249663Z",
          "iopub.status.idle": "2023-08-18T20:14:41.255693Z",
          "shell.execute_reply": "2023-08-18T20:14:41.254862Z"
        },
        "origin_pos": 6,
        "tab": [
          "pytorch"
        ],
        "id": "b6b758a3"
      },
      "outputs": [],
      "source": [
        "def pool2d(X, pool_size, mode='max'):\n",
        "    p_h, p_w = pool_size\n",
        "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            if mode == 'max':\n",
        "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
        "            elif mode == 'avg':\n",
        "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ff6470c",
      "metadata": {
        "origin_pos": 9,
        "id": "4ff6470c"
      },
      "source": [
        "We can construct the input tensor `X` in :numref:`fig_pooling` to [**validate the output of the two-dimensional max-pooling layer**].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8fcb17f0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:41.259009Z",
          "iopub.status.busy": "2023-08-18T20:14:41.258472Z",
          "iopub.status.idle": "2023-08-18T20:14:41.285891Z",
          "shell.execute_reply": "2023-08-18T20:14:41.285098Z"
        },
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "id": "8fcb17f0",
        "outputId": "5cc23641-7983-428e-f21e-cdf7402d713b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 5.],\n",
              "        [7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "pool2d(X, (2, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2660d3f7",
      "metadata": {
        "origin_pos": 11,
        "id": "2660d3f7"
      },
      "source": [
        "Also, we can experiment with (**the average pooling layer**).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "db997aec",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:41.289296Z",
          "iopub.status.busy": "2023-08-18T20:14:41.288755Z",
          "iopub.status.idle": "2023-08-18T20:14:41.294610Z",
          "shell.execute_reply": "2023-08-18T20:14:41.293875Z"
        },
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ],
        "id": "db997aec",
        "outputId": "89e095be-e28e-45b4-f39f-cd4b86266cc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "pool2d(X, (2, 2), 'avg')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12a5812d",
      "metadata": {
        "origin_pos": 13,
        "id": "12a5812d"
      },
      "source": [
        "## [**Padding and Stride**]\n",
        "\n",
        "As with convolutional layers, pooling layers\n",
        "change the output shape.\n",
        "And as before, we can adjust the operation to achieve a desired output shape\n",
        "by padding the input and adjusting the stride.\n",
        "We can demonstrate the use of padding and strides\n",
        "in pooling layers via the built-in two-dimensional max-pooling layer from the deep learning framework.\n",
        "We first construct an input tensor `X` whose shape has four dimensions,\n",
        "where the number of examples (batch size) and number of channels are both 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "163fc8d6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:41.298256Z",
          "iopub.status.busy": "2023-08-18T20:14:41.297476Z",
          "iopub.status.idle": "2023-08-18T20:14:41.304757Z",
          "shell.execute_reply": "2023-08-18T20:14:41.303750Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "id": "163fc8d6",
        "outputId": "b16bde2e-7551-4271-d61c-0dacd6eabaf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ 0.,  1.,  2.,  3.],\n",
              "          [ 4.,  5.,  6.,  7.],\n",
              "          [ 8.,  9., 10., 11.],\n",
              "          [12., 13., 14., 15.]]]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "613a9612",
      "metadata": {
        "origin_pos": 17,
        "id": "613a9612"
      },
      "source": [
        "Since pooling aggregates information from an area, (**deep learning frameworks default to matching pooling window sizes and stride.**) For instance, if we use a pooling window of shape `(3, 3)`\n",
        "we get a stride shape of `(3, 3)` by default.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc286034",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:41.308365Z",
          "iopub.status.busy": "2023-08-18T20:14:41.307491Z",
          "iopub.status.idle": "2023-08-18T20:14:41.314528Z",
          "shell.execute_reply": "2023-08-18T20:14:41.313528Z"
        },
        "origin_pos": 19,
        "tab": [
          "pytorch"
        ],
        "id": "bc286034",
        "outputId": "fc74b7fc-d91e-47ee-bd8f-70368bf799c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[10.]]]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pool2d = nn.MaxPool2d(3)\n",
        "# Pooling has no model parameters, hence it needs no initialization\n",
        "pool2d(X)\n",
        "\n",
        "# OUTPUT Expectation: 10\n",
        "# Why? Because we can only fit one 3x3 starting at the upper left corner and max value is 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02120224",
      "metadata": {
        "origin_pos": 22,
        "id": "02120224"
      },
      "source": [
        "Needless to say, [**the stride and padding can be manually specified**] to override framework defaults if required.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca0c78a7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:41.318117Z",
          "iopub.status.busy": "2023-08-18T20:14:41.317241Z",
          "iopub.status.idle": "2023-08-18T20:14:41.324934Z",
          "shell.execute_reply": "2023-08-18T20:14:41.323915Z"
        },
        "origin_pos": 24,
        "tab": [
          "pytorch"
        ],
        "id": "ca0c78a7",
        "outputId": "8153bdb5-35d7-46ba-ea5b-603b11be8124"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ 5.,  7.],\n",
              "          [13., 15.]]]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
        "pool2d(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4474180",
      "metadata": {
        "origin_pos": 27,
        "id": "c4474180"
      },
      "source": [
        "Of course, we can specify an arbitrary rectangular pooling window with arbitrary height and width respectively, as the example below shows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b31fea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:41.328395Z",
          "iopub.status.busy": "2023-08-18T20:14:41.327817Z",
          "iopub.status.idle": "2023-08-18T20:14:41.335285Z",
          "shell.execute_reply": "2023-08-18T20:14:41.334272Z"
        },
        "origin_pos": 29,
        "tab": [
          "pytorch"
        ],
        "id": "69b31fea",
        "outputId": "58e65793-b30c-4b0e-e3fa-2e99dda3a5a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ 5.,  7.],\n",
              "          [13., 15.]]]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
        "pool2d(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61da4755",
      "metadata": {
        "origin_pos": 32,
        "id": "61da4755"
      },
      "source": [
        "## Multiple Channels\n",
        "\n",
        "When processing multi-channel input data,\n",
        "[**the pooling layer pools each input channel separately**],\n",
        "rather than summing the inputs up over channels\n",
        "as in a convolutional layer.\n",
        "This means that the number of output channels for the pooling layer\n",
        "is the same as the number of input channels.\n",
        "Below, we will concatenate tensors `X` and `X + 1`\n",
        "on the channel dimension to construct an input with two channels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e54e620e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:41.338784Z",
          "iopub.status.busy": "2023-08-18T20:14:41.338035Z",
          "iopub.status.idle": "2023-08-18T20:14:41.345454Z",
          "shell.execute_reply": "2023-08-18T20:14:41.344440Z"
        },
        "origin_pos": 34,
        "tab": [
          "pytorch"
        ],
        "id": "e54e620e",
        "outputId": "9d2e0ca4-3e55-4b84-ad1c-9b52ffc42a51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ 0.,  1.,  2.,  3.],\n",
              "          [ 4.,  5.,  6.,  7.],\n",
              "          [ 8.,  9., 10., 11.],\n",
              "          [12., 13., 14., 15.]],\n",
              "\n",
              "         [[ 1.,  2.,  3.,  4.],\n",
              "          [ 5.,  6.,  7.,  8.],\n",
              "          [ 9., 10., 11., 12.],\n",
              "          [13., 14., 15., 16.]]]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = torch.cat((X, X + 1), 1)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3283101",
      "metadata": {
        "origin_pos": 36,
        "id": "d3283101"
      },
      "source": [
        "As we can see, the number of output channels is still two after pooling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87e7f759",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:41.349138Z",
          "iopub.status.busy": "2023-08-18T20:14:41.348332Z",
          "iopub.status.idle": "2023-08-18T20:14:41.355713Z",
          "shell.execute_reply": "2023-08-18T20:14:41.354667Z"
        },
        "origin_pos": 38,
        "tab": [
          "pytorch"
        ],
        "id": "87e7f759",
        "outputId": "156d88dd-507f-4a61-b9d2-08f2f72e3880"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ 5.,  7.],\n",
              "          [13., 15.]],\n",
              "\n",
              "         [[ 6.,  8.],\n",
              "          [14., 16.]]]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
        "pool2d(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fd9d3ec",
      "metadata": {
        "origin_pos": 42,
        "id": "0fd9d3ec"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Pooling is an exceedingly simple operation. It does exactly what its name indicates, aggregate results over a window of values. All convolution semantics, such as strides and padding apply in the same way as they did previously. Note that pooling is indifferent to channels, i.e., it leaves the number of channels unchanged and it applies to each channel separately. Lastly, of the two popular pooling choices, max-pooling is preferable to average pooling, as it confers some degree of invariance to output. A popular choice is to pick a pooling window size of $2 \\times 2$ to quarter the spatial resolution of output.\n",
        "\n",
        "Note that there are many more ways of reducing resolution beyond pooling. For instance, in stochastic pooling :cite:`Zeiler.Fergus.2013` and fractional max-pooling :cite:`Graham.2014` aggregation is combined with randomization. This can slightly improve the accuracy in some cases. Lastly, as we will see later with the attention mechanism, there are more refined ways of aggregating over outputs, e.g., by using the alignment between a query and representation vectors.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Implement average pooling through a convolution.\n",
        "1. Prove that max-pooling cannot be implemented through a convolution alone.\n",
        "1. Max-pooling can be accomplished using ReLU operations, i.e., $\\textrm{ReLU}(x) = \\max(0, x)$.\n",
        "    1. Express $\\max (a, b)$ by using only ReLU operations.\n",
        "    1. Use this to implement max-pooling by means of convolutions and ReLU layers.\n",
        "    1. How many channels and layers do you need for a $2 \\times 2$ convolution? How many for a $3 \\times 3$ convolution?\n",
        "1. What is the computational cost of the pooling layer? Assume that the input to the pooling layer is of size $c\\times h\\times w$, the pooling window has a shape of $p_\\textrm{h}\\times p_\\textrm{w}$ with a padding of $(p_\\textrm{h}, p_\\textrm{w})$ and a stride of $(s_\\textrm{h}, s_\\textrm{w})$.\n",
        "1. Why do you expect max-pooling and average pooling to work differently?\n",
        "1. Do we need a separate minimum pooling layer? Can you replace it with another operation?\n",
        "1. We could use the softmax operation for pooling. Why might it not be so popular?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a37fa6a",
      "metadata": {
        "origin_pos": 44,
        "tab": [
          "pytorch"
        ],
        "id": "8a37fa6a"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/72)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}